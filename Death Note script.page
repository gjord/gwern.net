---
title: Who wrote the 'Death Note' script?
description: Internal, external, stylometric evidence point to being real
created: 2 Nov 2009
tags: anime, statistics
status: in progress
belief: likely
...

<!-- REMINDER: if I have to redo all the Bayes calculations, use Laplace's correction in the first test! -->
<!--
TODO:
add titles to all movie & fanfiction links
link each free-form section to its statistical section and vice-versa
give where I got the derivation from - link Modafinil & vice-versa?
add link in index.page
-->
<!--
TODO: when finished with analysis, record final prediction (predictions: authorship, whether reply, and whether confirm/deny)
ping https://twitter.com/Cparlapanides
add 'experiment' to tags
ping the fanfiction authors with a link
ping the `stylo` people with a link
-->

Beginning in May 2009^[The earliest mention I've been able to find is a French site which [posted on 17 May 2009](http://web.archive.org/web/20090525025525/http://www.death-note.fr/home.php?page=news3) a translation of the beginning of the leaked script; no source is given, and it's not clear who did the translation, what script was used, or where the script was obtained. So while the script was clearly circulating by mid-May, I can't date the leak any earlier than date.] and up to October 2009, [there appeared online](http://www.animevice.com/news/rumor-alert-death-note-movie-script-leaked/2653/ "Rumor Alert: Death Note Movie Script Leaked?") a [PDF file](http://www.mediafire.com/?ce13d3xdazwxj09) ([mirror](http://dl.getdropbox.com/u/74617/Death%20Note%20Script.pdf)) claiming to be a script for the [Hollywood remake](!Wikipedia "Death Note (film)#Remake") of the _[Death Note](!Wikipedia)_ anime (see Wikipedia or my own little [Death Note Ending]() essay for a general description). Such a leak inevitably raises the question: is it genuine? Of course the studio had "no comment".

I was skeptical at first - how many unproduced screenplays get leaked? I thought it rare even in this Internet age - so I downloaded a copy and read it.

# Plot summary

The plot is curious. Ryuk and other [shinigami](!Wikipedia) are entirely omitted. Light Yagami is renamed "Luke Murray" (as expected of Greek writers like the Parlapanides?), and now lives in New York City, already in college. (Again, an appropriate setting for 2 screenwriters who grew up in New Jersey.) The plot is generally simplified.

What is more interesting is the changed emphases. Luke has been given a murdered mother, and much of his efforts go to tracking down the murderer (who, of course, escaped conviction for that murder). The Death Note is unambiguously depicted as a tool for evil, and a malign influence in its own right. There is minimal interest in the idea that Kira might be good. The Japanese aspects are minimized and treated as exotic curios, in the worst Hollywood tradition (Luke goes to a Japanese acquaintance for a translation of the kanji for 'shinigami', who, of course, being a primitive native, shudders in fear and flees the memsahib... oh, sorry, wrong era. But the description is still accurate.) [T-Mobile Sidekick](!Wikipedia) cellphones are mentioned and used a lot (6 times by my count).

The ending shows Luke using the memory-wiping gambit to elude L (who from the script seems much the same, although things not covered by the script, such as casting, will be critically important to making L, L), and finding the hidden message from his old self - but destroying the message before he learns where he had hidden the Death Note. It is implied that Luke has redeemed himself, and L is letting him go. So the ending is classic Hollywood pap.

The ending indicates someone who doesn't love _DN_ for its shades of gray mentality, its constant ambiguity and complexity. Any _DN_ fan feels deep sympathy for Light, even if they root for L and co. I suspect that if they were to pen a script, the ending would be of the 'Light wins everything' variety, and not this hackneyed sop. I know I couldn't bring myself to write such a thing, even as a parody of Hollywood.

In general, the dialogue is short and hackneyed. There are no excellent megalomaniac speeches about creating a new world; one can expect a dearth of ominous choral chanting in the movie. Even the veriest tyro of fanfiction could write more _DN_-like dialogue than this script did. (I should note that I have recanted of this assessment after looking through many _DN_ fanfictions for the stylometric analysis.)

Further, the complexities of ratiocination are largely absent, remaining only in the Lind L. Taylor TV trick of L and the famous eating-chips scene of Light. The tricks are even written incompetently - as written, on the bus, the crucial ID is seen by *accident*, whereas in _DN_, Light had written in the revelation of the ID quite specifically. The moral subtlety of _DN_ is gone; you cannot argue that Luke is a new god like Light. He is only an angry boy with a good heart lashing out, but by the end he has returned to the straight and narrow of conventional morality.

# Evidence

The question of authenticity falls under the honorable rubric of [textual criticism](!Wikipedia), which offers the handy distinction of [internal evidence](!Wikipedia) vs [external evidence](!Wikipedia).

## Internal

The first thing I noticed was that the 2 authors claimed on the PDF, "Charley and Vlas Parlapanides", was correct: they were the 2 brothers of whom it had been quietly [announced](http://www.variety.com/article/VR1118003063.html "Warner brings 'Death' to bigscreen: Studio acquires rights to Japanese manga series") in 30 April 2009 that they were hired to write it, confirming [the](http://hollywood.greekreporter.com/2008/07/12/the-brothers-parlapanides/ "The Brothers Parlapanides") [rumors](http://bloody-disgusting.com/news/12459/ "Vertigo Hires Scribes for 'Death Note' Remake") [of](http://blog.newsarama.com/2008/06/03/screen-bites-61/ "Vertigo Entertainment developing U.S. remake of Death Note") their June 2008 hiring. (And "Charley"? He was born "Charles", and much coverage uses that name. On the other hand, there *are* some media pieces using the diminutive, most prominently an [IMDb](http://www.imdb.com/name/nm0663048/) entry.)

Another interesting detail is the corporate address quietly listed at the bottom of the page: "WARNER BROS. / 4000 Warner Boulevard / Burbank, California 91522". That address is widely available on Google if you want to search for it, but one has to know about it in the first place and so it is much easier to just leave it out.

### PDF Metadata

(For the benefit of anyone attempting to replicate, the exact PDF I used has the [SHA-256](!Wikipedia) [hash](!Wikipedia "Cryptographic hash function"): `3d0d66be9587018082b41f8a676c90041fa2ee0455571551d266e4ef8613b08a`^[SHA-512: 954082c8cde2ccee1383196fe7c420bd444b5b9e5d676b01b3eb9676fa40427983fb27&#8203;ad8458a784ea765d66be93567bac97aa173ab561cd7231d8c017a4fa70].)

The second thing I did was take a look at the metadata[^death-note-metadata]:

- The creator tool checks out: "DynamicPDF v5.0.2 for .NET" is part of a commercial suite, and it was pirated well before April 2009, although I could not figure out when the commercial release was.
- The date, though, is "Thu 09 Apr 2009 09:32:47 PM EDT". Keep in mind, this leak was in May-October 2009, and the original _Variety_ announcement was dated 30 April 2009.

    If one were faking such a script, wouldn't one through either sheer carelessness & omission or by natural assumption (the Parlapanides signed a contract, the press release went out, and they started work) set the date well *after* the announcement? Why would you set it close to a month before? Wouldn't you take pains to show everything is exactly as an outsider would expect it to be? As [Jorge Luis Borges](!Wikipedia) writes in ["The Argentine Writer and Tradition"](http://dl.dropbox.com/u/85192141/1951-borges-argentinewriter.pdf):

    > Gibbon observes [in the _[Decline and Fall of the Roman Empire](!Wikipedia)_] that in the Arab book _par excellence_, the Koran, there are no camels; I believe that if there were ever any doubt as to the authenticity of the Koran, this lack of camels would suffice to prove it Arab. It was written by Mohammed, and Mohammed as an Arab had no reason to know that camels were particularly Arab; they were for him a part of reality, and he had no reason to single them out, while the first thing a forger or tourist or Arab nationalist would do is to bring on the camels - whole caravans of camels on every page; but Mohammed, as an Arab, was unconcerned. He knew he could be Arab without camels.

    Another small point is that the date is in the "EDT" timezone, or Eastern Daylight-savings Time: the Parlapanides have long been [based out of New Jersey](http://lacey.patch.com/articles/local-boys-make-good-in-tinseltown-with-immortals-75674a48), which is indeed in EDT. Would a counterfeiter have looked this up and set the timezone exactly right?

[^death-note-metadata]: The raw metadata can be extracted using [`pdftk`](http://www.pdflabs.com/tools/pdftk-the-pdf-toolkit/) like thus: `pdftk 2009-parlapanides-deathnotemovie.pdf dump_data`:

        InfoKey: Producer
        InfoValue: DynamicPDF v5.0.2 for .NET
        InfoKey: CreationDate
        InfoValue: D:20090409213247Z
        PdfID0: 9234e3f3316974458188a09a7ad849e3
        PdfID1: 9234e3f3316974458188a09a7ad849e3
        NumberOfPages: 112

### Writing/formatting

What of the actual play? Well, it is written like a screenplay, properly formatted, and the scene descriptions are brief but occasionally detailed like the other screenplays I've read (such as the _Star Wars_ trilogy's scripts). It is quite long and detailed. I could easily see a 2 hour movie being filmed from it. There are no obvious red flags: the spelling is uniformly correct, the grammar without issue, there are few or no common amateur errors like confusing "it's"/"its", and in general I see nothing in it - speaking as someone who has been paid on occasion to write - which would suggest to me that the author(s) were of professional caliber or skilled amateurs.

The time commitment for a forger is substantial: the script is ~22,000 words, well-edited and formatted, and reasonably polished. For comparison, [NaNoWriMo](!Wikipedia) tasks writers with producing 50,000 words of pre-planned, unedited, low-quality content in one month, with a second month ([NaNoEdMo](http://www.nanoedmo.net/)) devoted to editing. So the script represents at a minimum a month's work - and then there's the editing, reviewing, and formatting (and most amateur writers are not familiar with screenwriting conventions in the first place).

So much for the low-hanging fruit of internal evidence: all suggestive, none damning. A forger *could* have randomly changed Charles to "Charley", looked up an appropriate address, edited the metadata, come up with all the Hollywood touches, wrote the whole damn thing (quite an endeavour since relatively little material is borrowed from _DN_), and put it online.

### Stylometrics

The next step in assessing internal evidence is hardcore: we start running [stylometry](!Wikipedia) tools on the leaked script to see whether the style is consistent with the Parlapanides as authors. The PDF is 112 images with no text provided; I do not care to transcribe it by hand. So I split the PDF with `pdftk` to upload both halves to [Google Docs](http://googledocs.blogspot.com/2010/06/optical-character-recognition-ocr-in.html) (which has an [upload size limit](http://support.google.com/drive/bin/answer.py?hl=en&answer=176692)) to download its [OCR'ed](!Wikipedia "Optical character recognition") text; and then ran the PDF through [GOCR](!Wikipedia) to compare - the Google Docs transcript was clearly superior even before I spellchecked it. (In a nasty surprise halfway through the process, I found that for some reason, Google Docs would only OCR the first 10 pages or so of an upload - so I wound up actually uploading *12* split PDFs and recombining them!)

Samples of the Parlapanides' writing is hard to obtain; the only produced movie with their script is the 2000 _Everything For A Reason_ and the 2011 [_Immortals_](!Wikipedia "Immortals (2011 film)") (so any analysis in 2009 would've been difficult). I could not find the script for either available anywhere for download, so I settled for `OpenSubtitles.org`'s subtitles in [.srt](!Wikipedia) format and stripped the timings: `grep -v [0-9] Immortals.2011.DVDscr.Xvid-SceneLovers.srt  > 2011-parlapanides-immortals.txt` (There are no subtitles available for the other movie, it seems.)

Samples of fanfiction are easy to acquire. [Fanfiction.net's _Death Note_ section](http://www.fanfiction.net/anime/Death-Note/) (24,246 fanfics), sort by: number of favoriting users, completed, in English, and >5000 words. This yields 2,028 results but offers no way to filter by fanfictions written in a screenplay or script style, and no entry in the first 5 pages mentions "script" or "screenplay" so it is a dead end. Googling `"Death Note" (script OR screenplay OR teleplay) -skit site:fanfiction.net/s/` offers 8,990 hits, unfortunately, the overwhelming majority are either irrelevant (eg. using "script" in the sense of cursive writing) or too short or too low quality to make a plausible comparison. (I also submitted a [Reddit request](http://www.reddit.com/r/FanFiction/comments/122qeg/request_death_note_scripts_or_telescreenplays/), which yielded no suggestions.) The final selection:

- http://www.fanfiction.net/s/5482398/1/Death-Note-Movie-Spoof-Script
- http://www.fanfiction.net/s/7074737/1/School-Crack-Death-Note
- http://www.fanfiction.net/s/4684092/1/The-Sweet-Tooth-Show
- http://www.fanfiction.net/s/7429942/1/Death-Note-Behind-the-Scenes
- http://www.fanfiction.net/s/5163381/1/L-s-Pregnancy
- http://www.fanfiction.net/s/3790246/24/Death-Note-the-Abridged-Series
- http://www.fanfiction.net/s/5550717/1/Polly-Wants-A-Rosary
- http://www.fanfiction.net/s/8270904/1/Three-Characters
- http://www.fanfiction.net/s/5454328/9/The-Mansion
- http://www.fanfiction.net/s/4628655/1/The-Most-Wonderful-Time-Of-The-Year
- http://www.fanfiction.net/s/5779913/1/Whammy-Boy-s-Gone-Wild

As a control-control, I selected some fanfictions that I knew to be of high quality:

- http://www.fanfiction.net/s/5782108/1/Harry-Potter-and-the-Methods-of-Rationality
- http://www.fanfiction.net/s/5588986/1/
- http://www.fanfiction.net/s/5389450/1/The-Finale-of-the-Ultimate-Meta-Mega-Crossover
- http://www.fanfiction.net/s/5731071/1/Peggy-Susie
- http://www.fanfiction.net/s/7864670/1/
- http://www.fanfiction.net/s/7406866/1/To-the-Stars

The fanfictions were converted to text using [Web version FanFictionDownloader](http://www.fanfictiondownloader.net/webversion.php).

With 10 fanfictions, it makes sense to compare with 10 real movie scripts; if we didn't include real movie scripts formatted like movie scripts, one would wonder if all the stylometrics was doing was putting one script together with another. So in total, this worry is diluted by 3 factors (in descending order):

1. the use of 10 real movie scripts (as just discussed)
2. the use of 10 fanfictions resembling movie scripts to various degrees (previous)
3. the known Parlapanides work (the _Immortals_ subtitles) being pure dialogue and including no action or scene description which the stylometrics could "pick up on"

The scripts http://www.script-o-rama.com/table.shtml :

- http://www.dailyscript.com/scripts/fearandloathing.html
- http://www.angelfire.com/tx2/leeloo/5thelement.txt
- http://www.kokos.cz/bradkoun/movies/8mm.txt
- http://www.vietnamwar.net/84charliemopicscript.htm
- http://scifiscripts.com/scripts/twelvemonkeys.txt
- http://www.moviemalls.com/papers/13days.txt
- http://www.angelfire.com/movies/ridleyscott/script/1492-ConquestOfParadise.txt
- http://www.scifiscripts.com/scripts/2001.txt
- http://web.archive.org/web/20060517152008/http://www.wordsurge.com/The_Abyss.txt
- http://www.aellea.com/script/adventure.txt
- http://www.scifiscripts.com/scripts/banzai_script.txt

For the actual analysis, we use the [computational stylistics](http://sites.google.com/site/computationalstylistics/home) package of [R](!Wikipedia "R (programming language)") code; after downloading [`stylo`](http://sites.google.com/site/computationalstylistics/scripts), the analysis is pretty easy:

~~~{.R}
> install.packages("tcltk2")
> source("stylo_0-4-6_utf.r")
~~~

The settings[^R-stylo-settings] are to: run a [cluster analysis](!Wikipedia) which uses the entire corpus, assumes English, and looks at the difference between files in their use of "most popular words" (starting at 1 word & maxing out at 1000 different words, because the entire _Immortals_ subs is only ~4000 words of dialogue), where difference is a simple Euclidean distance.

[^R-stylo-settings]: Specifically, `config.txt` reads:

    ~~~{.R}
    corpus.format="plain"
    corpus.lang="English.all"
    analyzed.features="w"
    ngram.size=1
    mfw.min=1
    mfw.max=1000
    mfw.incr=1
    start.at=1
    culling.min=0
    culling.max=0
    culling.incr=20
    mfw.list.cutoff=5000
    delete.pronouns=FALSE
    analysis.type="CA"
    use.existing.freq.tables=FALSE
    use.existing.wordlist=FALSE
    consensus.strength=0.5
    distance.measure="EU"
    display.on.screen=TRUE
    write.pdf.file=FALSE
    write.jpg.file=FALSE
    write.emf.file=FALSE
    write.png.file=FALSE
    use.color.graphs=TRUE
    titles.on.graphs=TRUE
    dendrogram.layout.horizontal=TRUE
    pca.visual.flavour="classic"
    sampling="no.sampling"
    sample.size=10000
    length.of.random.sample=10000
    sampling.with.replacement=FALSE
    ~~~

The script PDF, full corpus, intermediate files, and `stylo` source code are available as a [7zipped tarball](http://dl.dropbox.com/u/85192141/deathnotescript.tar.7z).

![The cluster analysis of the 30-strong corpus.](/images/deathnote-cluster.png)

The graphed results are unsurprising:

1. The movies cluster together in the top third
2. The _Death Note_ fanfics are also a very distinct cluster at the bottom
3. In the middle, splitting the difference (which actually makes sense if they are indeed more competently or "professionally" written), are the "good" fanfics I selected. In particular, the fanfics by [Eliezer Yudkowsky](!Wikipedia) are generally close together - vindicating the basic idea of inferring authorship through similar word choice.
4. Exactly as expected, the _Immortals_ subs and the leaked _Death Note_ script are as closely joined as possible, and they practically form their own little cluster within the movie scripts.

    This is important because it's evidence for 2 different questions: whether the known Parlapanides work is similar to the leaked script, and whether the leaked script is similar to any fanfictions rather than movies. We can answer the latter question by noting that it is grouped far away from any fanfiction (the only fanfiction in the cluster, the "Three Characters" fanfiction, is very short and formalized), even though Eliezer Yudkowsky (a published author) wrote several of the fanfictions and one of them (_Harry Potter and the Methods of Rationality_) is intended for publication and perhaps [even a Hugo award](http://predictionbook.com/predictions/6556 "HP MoR: MoR will win a Hugo for Best Novel 2013-2017").

That the analysis spat out the files together is evidence: there were 30 files in the corpus, so if we generated 15 pairs of files at random, there's just a $\frac{1}{15}=6.6\%$ chance of those two winding up together.

## External
### Dating

But is there any external evidence? Well, the timeline is right: hired around June 2008, delivered a script in early April 2009, official announcement in late April 2009. How long *should* delivery take? The interval seems plausible: Figure about 2 months for both brothers to read through the _DN_ manga or watch the anime twice, clear up their other commitments, a month to brainstorm, 3 months to write the first draft, a month to edit it up and run it by the studio, and we're at 7 months or around February 2009. That leave a good 6 months for it to float around offices and get leaked, and then come to the wider attention of the Internet.

### Credit

Given this effort and the mild news coverage of it, one might expect a forger to take considerable pride in his work and want to claim credit at some point for a successful hoax. But as of October 2012, I am unaware of anyone even alluding or hinting that they did it.

### Official statements

Additional evidence comes from the January 2011 [announcement by Warner Bros](http://www.deadline.com/2011/01/warner-bros-taps-shane-black-for-japanese-manga-death-note/ "Warner Bros Taps Shane Black For Japanese Manga 'Death Note'") that the new director was one [Shane Black](!Wikipedia), and the script was now being written by Anthony Bagarozzi and Charles Mondry (with presumably the previous script tossed):

> "It's my favorite manga, I was just struck by its unique and brilliant sensibility," Black said. "What we want to do is take it back to that manga, and make it closer to what is so complex and truthful about the spirituality of the story, versus taking the concept and trying to copy it as an American thriller. Jeff Robinov and Greg Silverman liked that." Black's repped by WME and GreenLit Creative.

[ANN](http://www.animenewsnetwork.com/news/2011-10-31/director/warner-death-note-is-still-in-the-works "Director: Warner's Death Note Is Still in the Works") [quoted Black](http://www.animenewsnetwork.com/interest/2011-11-02/shane-black-describes-changes-he-opposed-to-warner-death-note "Shane Black Describes Changes He Opposed to Warner's Death Note") at a convention panel:

> However, Black added that the project was in jeopardy because the studio initially wanted to lose "the demon [Ryuk]. [They] don't want the kid to be evil... They just kept qualifying it until it ceased to exist." Black said that "the creation of a villain, the downward spiral" of the main character Light has been restored in the script, and added that this is what the film should be about.'
>
> ...According to the director of _[Kiss Kiss Bang Bang](!Wikipedia)_ and the upcoming _[Iron Man 3](!Wikipedia)_ film, the studios initially wanted to give the main character Light Yagami a new background story to explain his "downward spiral" as a villain. The new background would have had a friend of Light murdered when he was young. When Light obtains the Death Note - a notebook with which he can put people to death by writing their names - he uses it to seek vengeance. However, Black emphasized that he opposed this background change and the suggested removal of the Shinigami (Gods of Death), and added that neither change is in his planned version.

Black's comments line up well with the leaked script: Ryuk is indeed omitted entirely, Light is indeed mostly good and redeemed, Light does have a backstory justifying his vengeance, and so on. The only discordant detail is that in the leaked script, it was his mother murdered and not "a friend".

### Legal takedowns

The original _Anime Vice_ article had commenters provide two `sendspace` links for downloading the script. Both files went dead quickly, and an uploader wrote ["WB took it down that proves it is not fake"](http://www.animevice.com/death-note-hollywood-live-action/13-1374/rumor-alert-death-note-movie-script-leaked/97-207040/#js-post-body-116650). The `sendspace` links merely say that the files are no longer available, without giving any explicit reason like a [DMCA](!Wikipedia) takedown.

Assuming it was a DMCA takedown, who did it? Not the 2 brothers, who might have a legal right to order the takedown of material falsely attributed to them (I am not clear on the remedies available for a false attribution of authorship), but surely either the commissioning studio or their partner. Needless to say, they do not have a standing RIAA-style war against _DN_ fanfiction or fan-art or even torrents of the anime or scanlations of the manga; just this script. (Possibly if the script were not the studio's property, it wouldn't have any legal ground to demand takedowns - their license likely covers just the movie rights, and so fanfiction in the form of a script (for example) would infringe on the Japanese rights-holder, not the studio.)

The [same uploader](http://www.animevice.com/death-note-hollywood-live-action/13-1374/rumor-alert-death-note-movie-script-leaked/97-207040/?page=2#js-post-body-117149) says:

> I called Warner Bros After all the channels at WB, i finally got to the WB backed company Producing DN Dan Lin Pictures i gave them a chance to clear the air on the leaked script, to prove or disprove it they said  "no comment at this time"

The original _Anime Vice_ author wrote

> Rather than run with the story then, I called Lin Pictures to see if they could confirm or deny whether the script was actually theirs or a fan-written phony. I was told I would get a call back, but never did. I tried calling back a second time earlier this week, this time passing on considerably more information, and still no call back. As such, I have come to the conclusion that the company isn't overly concerned with the script, which suggests several possibilities to me:
>
> 1. It's not a legitimate script at all, so they're not worried about it.
> 2. It's an old draft, significantly different from the current version, so they're not worried about it.
> 3. The script was intentionally leaked for promotional purposes or to gauge fan reaction.

I don't buy it. If it is a fake script, why not simply deny it - either time? It is not as if companies usually have any trouble denying things. A "no comment" is more consistent with it being real and them also sending takedowns.

I find this external legal evidence compelling, and in conjunction with the internal evidence and oddities best explained by the leaked script being authentically by said Hollywood scriptwriters, I believe the script real. Perhaps an early draft to be discarded or rewritten, but still genuine. I suppose an American _DN_ movie could be much worse: just consider _[Dragon Ball Evolution](!Wikipedia)_ or _[The Last Airbender](!Wikipedia)_!

# Analysis

We could leave matters there with a bald statement that the evidence is "compelling", but [Richard Carrier](!Wikipedia) recently offered in _Proving History: Bayes's Theorem and the Quest for the Historical Jesus_ (2012; [2008 handout](http://www.richardcarrier.info/CarrierDec08.pdf "Bayes's Theorem for Beginners: Formal Logic and Its Relevance to Historical Method")) an inspiring example of how matters of history and authorship could be more rigorously investigated with some simple statistical thinking, and there's no reason we cannot try to give some rough numbers to each previous piece of evidence. Even if we can only agree on whether a piece of evidence is for or against the hypothesis of the Parlapanides' authorship, and not how strong a piece of evidence it is, the analysis will be useful in demonstrating how converging weak lines of reasoning can yield a strong conclusion.

## Priors

The first piece of evidence is that the leak exists in the first place.

Extraordinary claims require extraordinary evidence, but ordinary claims require only ordinary evidence: a claim to have uncovered [Hitler's lost diaries](!Wikipedia "Hitler Diaries") 40 years after his death is a remarkable discovery and so it will take more evidence before we believe we have the private thoughts of the Fuhrer than if one finds what purports to be one's sister's diary in the attic. The former is a unique historic event as most diaries are found quickly, few world leaders keep diaries (as they are busy world-leading), and there is large financial incentive (9 million Deutschmarks or ~$13.6m 2012 dollars) to fake such diaries (even in 60 volumes). The latter is not terribly unusual as many females keep diaries and then lose track of them as adults, with fakes being almost unheard of.

How many leaked scripts end up being hoaxes or fakes? What is the [base rate](!Wikipedia)?

Leaks seem to be common in general. Just googling "leaked script", I see recent incidents for _Robocop_, _Teenage Mutant Turtles_, _Mass Effect 3_ (confirmed by Bioware to have been real), _Les MisÃ©rables_, _Jurassic Park IV_ (concept art), _Batman_[^Nolan], and _Halo 4_. A [blog post](http://www.mandatory.com/2012/07/13/the-final-verdict-on-10-famously-leaked-scripts/) makes itself useful by rounding up 10 old leaks and assessing how they panned out: 4 turned out to be fakes, 5 real, and 1 (for _The Master_) unsure. Assuming the worst, this gives us $\frac{5}{10}$ are real or 50% odds that a randomly selected leak would be real. Given the number of "draft" scripts on [IMSDb](http://www.imsdb.com/), 50% may be low. But we will go with it.

[^Nolan]: The fake _Batman_ script is pretty weird; it starts off interesting and has many good parts, but then flounders in opaqueness and concludes even more weirdly with far too much material in it for a single film to plausibly include. If it were supposed to be by anyone but Christopher Nolan, you'd comment "this can't be real - the plot is too flabby and confusing, and the dialogue veers into non sequiturs and half-baked philosophy" (which of course it is). But one expects that of Nolan, almost, and for the filmed movie to be better than the script, so paradoxically, the worsening quality may have lent it some credibility.

## Internal evidence
### Authorship

How would we estimate the evidence of "Charley Parlapanides"? The names of the writers could either be:

1. present and wrong

    Very strong evidence it is fake: who puts their own name down wrong? This would be overwhelming evidence, but we don't have it so we will drop this possibility from consideration and consider the remaining possibilities:
2. present and right

     Evidence it is real. Of the 10 scripts used in the stylometric, $\frac{9}{10}$ included right authorship information.
3. not present

    Of the 4 known fake scripts mentioned previously, only 2 included authorship information.

Given this information, how does the presence of right authorship influence our prior belief of 50%?

Let _a_ be "is real" and _b_ be "has correct authorship". We want to know the probability of _a_ given the observation "correct authorship". Bayes' theorem:

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))}$

If you look, the right-hand side of that equation has exactly 4 pieces in its puzzle:

1. $P(a)$

    This is something we already know, 'probability of being real". This is the base rate we already estimated at 50% or 0.5.
2. $P(\lnot a)$

    This is the negation of the previous. What is the negation of 50%, its contrary? 50%.
3. $P(b|a)$

    Remember, we read the pipe notation *backwards*, so this is 'the probability that a real script (_a_) will include authorship' (_b_)'. We said that $\frac{9}{10}$ of good scripts include authorship, so this is 90% or 0.9. (One way to compensate for the small sample size of 10 scripts would be to use [Laplace's rule of succession](!Wikipedia), $\frac{n+1}{m+2}$, which would yield $\frac{9+1}{10+2}= 0.83$.)
4. $P(b|\lnot a)$

    Finally, we have 'the probability that a fake script will include authorship". We looked at 4 fake scripts and 2 included authorship, which is another 50% or 0.5.

To put all these definitions in a list:

1. _a_ = is real
2. _b_ = has authorship
3. $P(a)$ = probability of being real = 50% = 0.50
4. $P(\lnot a)$ = probability of being not real = 50% = 0.50
5. $P(b|a)$ = probability a real script will include authorship = 90% = 0.9
6. $P(b|\lnot a)$ = probability a fake script will include authorship = 50% = 0.5

We substitute in to the original equation:

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} = \frac{0.9 \times 0.5}{(0.9 \times 0.5) + (0.5 \times 0.5)} = \frac{0.45}{0.45 + 0.25} = \frac{0.45}{0.7} = 0.643$

Sanity checks:

1. Authorship is evidence *for* it being real; did we increase our confidence that the script is real?

    Yes, because 64.3% > 50%. So we moved the right direction.
2. Did we move the right amount?

    Well, the fake scripts have a 50% rate and the real scripts have 90%; since this is the only evidence we've taken into account so far, our first calculation shouldn't move us "very far", whatever that means, since not all real scripts have authorship and plenty of fake ones are careful to include them. (Imagine a world where 80% of fakes include authorship: authorship would become even weaker evidence; and when fakes hit 90% inclusion, authorship would be so weak as to be no evidence at all since the fakes and reals look exactly the same.) The inclusion of authorship does not seem like tremendous evidence so after taking authorship into account, we should be close to our original prior of 50% than to any extreme certainty like 90%.

    Are we? Our posterior of 64% doesn't strike me as a *big* shift from 50%, so we conclude that this second sanity check is satisfied. Good!

A final calculation: the probability that "a test gives a true positive" divided by "the probability that a test gives a false positive" ($\frac{P(b|a)}{P(b|\lnot a)}$) is the "[likelihood ratio](!Wikipedia)" of that test. A likelihood ratio of 1 indicates that our test is useless as it is equally likely for real scripts and fake scripts alike; <1 indicates it is evidence *against* being real, and >1 evidence *for* being real. Likelihood ratios will be useful later TODO, so we'll calculate them too as we go along. So:

$\frac{P(b|a)}{P(b|\lnot a)} = \frac{0.9}{0.5} = 1.8$

(As expected of evidence for the script being real, the likelihood ratio > 1.)

#### Author spelling

I remarked that the use of "Charley" was interesting since there were multiple ways to spell his name. Does this spelling serve as evidence for authenticity? It turns out: no! It is either irrelevant or evidence against.

To use "Charley" as evidence, we need to know what the real man would be more or less likely to write, and what fakes would be more or less likely to write. I have been unable to find out the "ground truth" here; all 3 variants are used in Google:

- "Charles": 11,800 hits
- "Charley": 182,000 hits
- "Charlie": 1,440 hits

I suspect the truth is probably "Charles" since his [Twitter account](http://twitter.com/Cparlapanides) uses "Charles"; his [IMDb](http://www.imdb.com/name/nm0663048/) page lists 5 credits "as Charles Parlapanides" (but nevertheless calls him "Charley").

What question would we ask here? We could put it as: if we make the assumption that the real man has an even chance of using either "Charles" or "Charlie"/"Charley", while a fake would choose based on the Google hits (unaware of the variants), how would we change our belief upon observing the script's use of "Charley"?

1. _a_ = is real
2. _b_ = name is spelled "Charley"
3. $P(a)$ = probability of being real = 64% = 0.64
4. $P(\lnot a)$ = probability of being not real = 1 - 0.64 = 0.36
5. $P(b|a)$ = probability a real script will include "Charley" = 50% ("even chance") = 0.5
6. $P(b|\lnot a)$ = probability a fake script will include "Charley" = $\frac{182000}{182000+11800+1440}$ = 0.93

Substitute:

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} = \frac{0.5 \times 0.64}{(0.5 \times 0.64) + (0.93 \times 0.36)} = \frac{0.32}{0.32 + 0.3348} = \frac{0.32}{0.6548} = 0.49$

That really hurt the probability, since by assumption using the popular spelling is so heavily correlated with a fake.

Likelihood ratio:

$\frac{P(b|a)}{P(b|\lnot a)} = \frac{0.5}{0.93} = 0.538$

(We realized the name variant was evidence against, and accordingly, the likelihood ratios < 1.)

#### Corporate address

Googling "Warner Brothers address" turns up the address used in the PDF as the second hit (it seems to be the official address of all Warner Bros. operations), so we can assume that any faker can find it - *if* they thought to include it. This question is simply: is a corporate address included? Checking, we see addresses are rare:
of the real, $\frac{1}{10}$; of the fakes, fakes: $\frac{0}{4}$.

1. _a_ = is real
2. _b_ = has address
3. $P(a)$ = probability of being real = 0.49
4. $P(\lnot a)$ = probability of being not real = 1 - 0.49 = 0.51
5. $P(b|a)$ = probability a real script will include an address = $\frac{1}{10}$; we apply Laplace's Rule of Succession to get $\frac{1+1}{10+2} = \frac{2}{12} = 0.16$
6. $P(b|\lnot a)$ = probability a fake script will include address = $\frac{0}{4}$; we apply Laplace (as before) to get $\frac{0+1}{4+2}$ = $\frac{1}{6}$ = 0.16

Substitute:

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} = \frac{0.16 \times 0.49}{(0.16 \times 0.49) + (0.16 \times 0.51)} = \frac{0.0784}{0.0784 + 0.0816} = \frac{0.0784}{0.16} = 0.49$

0.49? But that was what we started with! It turns out that we are working with such a small sample that when we correct with Laplace's law, we learn that there are so few instances of screenplays floating around with corporate addresses in them, we actually can't infer anything from it. Does the likelihood ratio agree?

$\frac{P(b|a)}{P(b|\lnot a)} = \frac{0.16}{0.16} = 1$

(Here we see the final category of likelihood ratios: neither greater than nor less than 1, but equal to 1 - and thus not evidence for nor against.)

#### PDF date

We noted the curious fact that while the Parlapanides' work on the script was announced on *30* April, the PDF claims a date of *9* April.

I did not expect this inversion, but thinking about it in retrospect, this seems consistent with the script being real: the studio commissioned them to write a script, they turned in material, the studio liked it, and the official word went out. (Presumably had the studio disliked it, they would've been quietly paid a small sum and a new writer tried.) An ordinary person like me, however, would date any forgery to after the announcement, reasoning that it would be "safe" to date any script to after the announcement.

So we want to express that this inversion is evidence for the script being real, and that frauds would be dated as one would normally expect. If I were to set out to make a fraud, I don't think I would tinker that way with the PDF date even once out of 20 times, but let's be very conservative and say a mere 75% of fake scripts would have a normal date (that is: 25% of the time, the faker would be clever enough to invert the dates); and let's say there was a 50% chance that the real script would be inverted (since we don't know the real frequency of inversion). The core assumption here is that inversion is more likely for real scripts than fake scripts, an assumption I feel is highly likely (what faker would dare such a blatant inconsistency? It's Gibbon & the camels again but in a stronger form.) We know how to run the numbers now:

1. _a_ = is real
2. _b_ = the date is inverted
3. $P(a)$ = probability of being real = 0.49
4. $P(\lnot a)$ = probability of being not real = 1 - 0.49 = 0.51
5. $P(b|a)$ = probability a real script will be inverted = 50% = 0.5
6. $P(b|\lnot a)$ = probability a fake script will be inverted = 25% = 0.25

Substitute:

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} = \frac{0.5 \times 0.49}{(0.5 \times 0.49) + (0.25 \times 0.51)} = 0.65772$

A jump from 49% to 65.8% is a respectable jump for such a weird date. Then the likelihood ratio is:

$\frac{P(b|a)}{P(b|\lnot a)} = \frac{0.5}{0.25} = 2$

#### PDF creator tool

The creator tool was released and pirated before the creation date. It may not seem informative - how could the PDF be created *before* the PDF generator was written? - but it actually is: it tells us that this was not a careless fraud where the person installed the latest & greatest PDF generator, wrote a script, edited the date, and didn't realize that the creating generator & version number was included as well. If the version number had been of a program released anywhere between April and October^[Modulo the previously discussed issue that the leaked script seems to have been circulating in *May* 2009, which would drastically cut down the window to a month or less.] 2009, then this would be a glaring red flag warning that the PDF was fake! In all real PDFs, the generator tool would be *before* the file creation date; but in many fake PDFs, this would be inverted. The case of interest is where the fake author installs a new program between April and October, and then fails to notice the revealing metadata (a conjunction).

1. _a_ = is real
2. _b_ = date is not inverted
3. $P(a)$ = probability of being real = 0.658
4. $P(\lnot a)$ = probability of being not real = 1 - 0.658 = 0.342
5. $P(b|a)$ = probability a real script will include non-inverted date = 0.99 (why not 100%? Well, shit happens.)
6. $P(b|\lnot a)$ = probability a fake script will include a non-inverted date = 1 - 0.0415 = 0.9585

    This is a hard estimate. Let's think about the opposite: what is the chance that a faker *will* invert date? What leads to that happening? Suppose everyone replaces their computer every 5 years; what is the chance this replacement (and ensuring upgrade of all software) happens in the 5 month window between April and October 2009? Well, it's $\frac{5}{5 \times 12} = \frac{1}{12}$. What's the chance they then fail to notice? Unless they're really skilled I'd expect them to usually miss it, but let's be conservative and say they usually notice it and fix it, and have only a 40% chance of missing it. An inversion requires both the upgrade (8.3%) and then a miss (40%) for a final chance of 4.15%! This is so small that we know in advance that it's not going to make a big difference and may not have been worth thinking about.

$\frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} = \frac{0.99 \times 0.658}{(0.99 \times 0.658) + (0.9585 \times 0.342)} = 0.66524$

And indeed, 0.665 is not very much larger than 0.658.

Likelihood ratio:

$\frac{P(b|a)}{P(b|\lnot a)} = \frac{0.99}{0.9585} = 1.033$

(As expected of such weak evidence, it's hardly different from 1.)

#### PDF timezone

The date being set in the right timezone is another piece of evidence: a fraud could live pretty much anywhere in the world and his computer will set the PDF to the wrong timezone and he'd have to remember to manually set it to the "right" timezone, while the Parlapanides live in New Jersey and will likely have their PDF timezone set appropriately (even if they travel, as they must, their computers may not go with them, or if the computers go with them, may not change their timezone settings, or if the computers go with them and change their timezone, they may not create the PDF during the trip). So this definitely seems like at least weak evidence.

How to estimate the chance that the fake author would live in a different timezone? If the fraud lived in the US (as is overwhelmingly likely and I'll assume for the sake of conservatism), the US spans something like 6 distinct timezones. Timezones split up roughly by states so people can estimate the population per timezone; stealing [one such estimate](http://answers.google.com/answers/threadview?id=714986 "Q: Population statistics by time zone"):

1. CST: 85385031
2. MST: 18715536
3. PST: 48739504
4. thus, non-EST: 152840071
5. EST: 141631478
6. thus, total population: 152840071+141631478=294471549

    The US population is more like 312 million than 294 million but the difference isn't important: what is important is the size of EST compared to the rest of the population.

So, the problem setup becomes:

1. _a_ = is real
2. _b_ = is EDT
3. $P(a)$ = probability of being real = 0.665
4. $P(\lnot a)$ = probability of being not real = 1 - 0.665 = 0.3349
5. $P(b|a)$ = probability a real script will be in EDT = 99% (shit happens) = 0.99
6. $P(b|\lnot a)$ = probability a fake script will be in EDT *xor* the faker will remember to edit the timezone = $\frac{141631478}{294471549}$ xor 0.4 (we assume 0.4 because we used it last time for the PDF creator tool) = 0.481 + 0.4  = 0.881

Substitute:

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} = \frac{0.99 \times 0.665}{(0.99 \times 0.665) + (0.881 \times 0.3349)} = 0.691$

This would have been a much bigger update than 2.6% (from 66.5% to 69.1%) if the evidence of the timezone hadn't been neutered by our assumption that most fakers would be clever enough to edit it. But anyway, the likelihood ratio:

$\frac{P(b|a)}{P(b|\lnot a)} = \frac{0.99}{0.881} = 1.1237$

#### Writing/formatting

We could isolate multiple tests here:

1. length

    Some of the fake scripts are very long and complete; I remarked in an earlier footnote that the fake _Batman_ script is actually *too* long for a movie. One of the fake scripts was a single leaked page, making for a $\frac{3}{4}$ rate.
2. formatting

    The sample of real scripts has been reformatted for Internet distribution and doesn't include the "original" PDFs or representations thereof; worse, the 4 or 5 fake scripts are all properly formatted. With the existing corpus, this test turns out to be useless!

    With the dubious benefit of hindsight, we might claim this is not a surprise: after all, any script without formatting would be "obviously" a fake and one would never hear about it. One only hears about plausible fakes which possess at least the basic surface features of a real script.
3. writing quality (spelling & grammar)

    In addition, the fake scripts are well-written. Like formatting, this turns out to be a bad indicator; someone writing a movie-length script seems to also be the sort of person who can write well. The description of one of the fakes is interesting in this regard:

    > This is probably one of the most elaborate ruses on the list. The script was written by 27-year-old Los Angeles writer Justin Becker, and as far as we can tell, he did it for laughs. Becker traveled across the West Coast, planting his scripts all over bookstores, hoping they would get discovered. He basically thought, "it would be funny to find out that a _Mr. Peepers_ movie had been written, and it was very serious and pretentious and political, and it had been shelved because of 9/11" (_SF Weekly_), which is explained in the preface of the script and by the fact that the screenplay was supposedly written one day before September 11th, 2001 and contained George W. Bush in the story.

This leaves just length as a test:

1. _a_ = is real
2. _b_ = is full-length
3. $P(a)$ = probability of being real = 0.691
4. $P(\lnot a)$ = probability of being not real = 1 - 0.691 = 0.309
5. $P(b|a)$ = probability a real script will be full-length = 99% (not 100%: shit happens) = 0.99
6. $P(b|\lnot a)$ = probability a fake script will be full-length = $\frac{3}{4}$, by Laplace, $\frac{3+1}{4+2} = \frac{4}{6}$ = 0.66

Substitute:

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} = \frac{0.99 \times 0.691}{0.99 \times 0.691 + 0.66 \times 0.309} = 0.7703$

Likelihood ratio:

$\frac{P(b|a)}{P(b|\lnot a)} = \frac{0.99}{0.66} = 1.5$

#### Plot

The earlier plot summary conveyed the "Hollywood" feel of the plot but unfortunately it's hard to judge from localization: a _DN_ fan attempting to imitate a Hollywood-targeted script might rename Light to "Luke", might simplify the plot considerably (there is precedent in the Japanese live-actions movies [_Death Note_](!Wikipedia "Death Note (film)#Death Note"), [_Death Note: The Last Name_](!Wikipedia "Death Note (film)#Death_Note: The Last_Name") & _[L: Change the World](!Wikipedia)_), might set it in NYC (Tokyo is obviously out of the question, and NYC seems to be a default location of crime-related movies), and so on.

More importantly, the plot includes several [idiot-ball](http://tvtropes.org/pmwiki/pmwiki.php/Main/IdiotBall)-related changes that I think any _DN_ fan competent enough to write this fake would never have made, even in the name of localization and Hollywoodization: the incompetent bus ID trick comes to mind.

Unfortunately, in both respects, I can't assign defensible numbers to my interpretation for the simple reason that any reasonable differences in probabilities leads to a ridiculously strong conclusion!

For example, if I gave 90% (fakes) vs 95% (real) for the individual localization points (for each of name, simplification, location), and then 10% (fakes) vs 50% (real) for 2 instances of incompetence, this gives us a likelihood ratio of:

$\frac{0.95}{0.90} + \frac{0.95}{0.90} + \frac{0.95}{0.90} + \frac{0.10}{0.50} + \frac{0.10}{0.50} = 3.5667$

(Here we see an advantage of likelihood ratios: they're easy to calculate and give us an indicator of argument strength *without* having to run through 5 different iterations of Bayes's theorem.)

A likelihood ratio of 3.6 would be the single strongest set of arguments we have seen yet, and even stronger than the stylometric likelihood ratio in the next section. If we used this result, it would be solely responsible for a very large amount of the conclusion. A critic of the final conclusion would be right to wonder if the conclusion rested solely on this dubious and unusually subjective section, so we will omit it (with the understanding that as usual, we are being conservative and essentially trying to calculate a lower bound).

#### Stylometrics

This is straightforward: if a fake script gets paired up randomly, then it had just a $\frac{1}{15}$ chance of pairing up with _Immortals_. Even if we restrict the matches to the other movie scripts, there were 10 movie scripts and 2 oddballs for 12 total or 6 pairings, giving $\frac{1}{6}$ chance of randomly pairing up with _Immortals_. The real question is: if the script is real, what chance does it have of pairing up with something else by the same authors? I included 4 fanfictions by the same author (Eliezer Yudkowsky), and 2 wound up pairing (with the other 2 in the same overall cluster but more distant from the pair and each other), giving a rough guess of 50%; this is convenient since our default "I have no idea at all" guess for any binary question is 50%, and even if we apply Laplace, we still get 50% ($\frac{2+1}{4+2} = \frac{3}{6}$ = 50%). So as usual, we will make the most conservative assumption for the fake, and keep our pessimistic assumption about the real.

1. _a_ = is real
2. _b_ = is paired with _Immortals_
3. $P(a)$ = probability of being real = 0.7703
4. $P(\lnot a)$ = probability of being not real = 1 - 0.7703 = 0.2297
5. $P(b|a)$ = probability a real script will be paired with _Immortals_ = 50% = 0.50
6. $P(b|\lnot a)$ = probability a fake script will paired with _Immortals_ = $\frac{1}{6}$ = 0.1667

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} = \frac{0.50 \times 0.7703}{(0.50 \times 0.7703) + (0.1667 \times 0.2297)} = 0.9096$

$\frac{P(b|a)}{P(b|\lnot a)} = \frac{0.50}{0.1667} = 2.999$

As expected, the stylometrics was powerful evidence.

## External evidence
### Dating

The argument here seems to be of the form that a PDF dated April 2009 is consistent with the estimated timeline for the true script. But what would be inconsistent? Well, a PDF dated *after* April 2009: such a PDF would raise the question "what exactly the brothers were doing from June 2008 all the way to this counterfactual post-April 2009 date?"

But it turns out we already used this argument! TODO:link We used it as the PDF date inversion test. Can we use the April date as evidence again and double-count it? I don't think we should since it's just another way of saying "April and earlier is evidence for it being real, post-April is evidence against", regardless of whether we justify pre-April dates as being during the writing period or as being something a forger wouldn't dare do. This argument turns out to be redundant with the previous internal evidence (which in hindsight, starts to sound like we ought to have classified it as external evidence).

What we *might* be justified in doing is going back to the PDF date inversion test and strengthening it since now we have 2 reasons to expect pre-April dates. But as usual, we will be conservative and leave out this strengthening.

### Credit

This is an interesting external argument as it's the only one dependent purely on the passage of time. It's a sort of [argument from silence](!Wikipedia), or more specifically, a [hope function](/docs/1994-falk "'The Ups and Downs of the Hope Function In a Fruitless Search', Falk et al 1994")

#### Hope function

The hope function is simple but exhibits some deeply counterintuitive properties (the focus of the psychologists writing the previously linked paper). Our case is the straightforward part, though. We can best visualize the hope function as a person searching a set of _n_ boxes or drawers or books for something which may not even be there (_p_). Obviously, if he finds the item, he now knows _p_=1 (it *was* there after all), and once he has searched all _n_ boxes without finding the thing, he knows _p_=0 (it wasn't there after all). Logically, the more boxes he searches without finding it, the more pessimistic he becomes (_p_ shrinks towards 0). How much, exactly?  Falk et al 1994  give a general formula for _n_ boxes of which you've searched _i_ boxes when your prior probability of the thing being there is _L~0~_:

$L_i = \frac{\frac{n - i}{n} \times L_0}{\frac{n - i}{n} \times L_0 + (1 - L_0)}$

So for example: if there's _n_=10 boxes, we searched _i_=5 without finding the thing, and we were only _L~0~_=50% sure the thing was there in the first place, our new guess about whether the thing was there:

$\frac{\frac{10 - 5}{10} \times 0.5}{\frac{10 - 5}{10} \times 0.5 + (1 - 0.5)} = \frac{0.5 \times 0.5}{0.5 \times 0.5 + 0.5} = \frac{0.25}{0.25 + 0.5} = \frac{0.25}{0.75} = \frac{1}{3} = 0.33$

In this example, 33% seems like a reasonable answer (and interestingly, it's not simply $50\% \times \frac{5}{10} = 25\%$).

### Credit & hope function

In the case of "taking credit", we can imagine the boxes as years, and each year passed is a box opened. As of October 2012, we have opened 3 boxes since the May/October 2009 leak. How many boxes total should there be? I think 20 boxes is more than generous: after 2 decades, the _DN_ franchise probably won't even be active^[Quick, of the anime aired 20 years ago [in](!Wikipedia "Category:1992 anime") [1992](http://www.anime-planet.com/anime/years/1992), how many are active franchises? Of the 48 on the first page, maybe 3 or 4 seem active.] - if anyone was going to claim credit, they probably would've done so by then. What's our prior probability that they will do so at all? Well, of the 4 faked scripts, the author of the _Mr. Peepers_ script took credit but the other 3 seem to be unknown - but it's early days yet, so we'll punt with a 50%. And of course, if the script is real, very few people are going to falsely claim authorship (thereby claiming it's fake?). So our setup looks like this:

1. _a_ = is real
2. _b_ = no one has claimed authorship
3. $P(a)$ = probability of being real = 0.9096
4. $P(\lnot a)$ = probability of being not real = 1 - 0.9096 = 0.0904
5. $P(b|a)$ = probability a real script will have no ownership claim = 99% (shit happens^[Or more precisely, sometimes people do falsely claim authorship and even sue studios over it; but if you picked 100 random scripts, would you expect to find more than 1 such instances? Keeping in mind most scripts never turn into movies but die in [development hell](!Wikipedia)!]) = 0.99
6. $P(b|\lnot a)$ = probability a fake script will have no ownership claim = probability someone *will* claim it is the hope function with _n_=20, _i_=3, _L~0~_=50% = $\frac{\frac{20 - 3}{20} \times 0.5}{\frac{20 - 3}{20} \times 0.5 + (1 - 0.5)} = 0.45945$, so the probability someone will *not* is $1 - 0.45945 = 0.54055$

Then Bayes:

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} = \frac{0.99 \times 0.9096}{(0.99 \times 0.9096) + (0.54055 \times 0.0904)} = 0.9485$

Likelihood ratio:

$\frac{0.99}{0.54055} = 1.831$

### Official statements

The 2011 descriptions of the plot of the real script match the leaked script in several ways:

1. no Ryuk or shinigamis

    This is an interesting change. I don't think it's likely a faker would remove them: without them, there's no explanation of how a Death Note can exist, there's no comic relief, some plot mechanics change (like dealing with the hidden cameras), etc. Certainly there's no reason to remove them because they're hard to film - that's what CGI is for, and who in the world does SFX or CGI better than Hollywood?
2. Light ends the story good and not evil
3. Light seeks vengeance

    Items 2 & 3 seem like they would often be connected: if Light is to be a good character, what reason does he have to use a Death Note? Vengeance is one of the few socially permissible uses. Of course, Light could start as a good character using the Death Note for vengeance and slide down to an evil ending, but it's not as likely.
4. Light seeking vengeance for a *friend* rather than his *mother*

    This item is contradictory, but only weakly so: a switch between mother and friend is an easy change to make, one which doesn't much affect the rest of the plot.

On net, these 4 items clearly favor the hypothesis of the script being real. But how much? How much would we expect the fan or faker to avoid Hollywood-style changes compared to actual Hollywood screenwriters like the Parlapanides?

This is the exact same question we already considered in the plot section of internal evidence! Now that we have external attestation that some of the plot changes I identified back in 2009 as being Hollywood-style are in the real script, can we do calculations?

I don't think we can. The external attestation proves I was right in fingering those plot changes as Hollywood-style, but this is essentially a massive increase in $P(b|a)$ (the chance a real script will have Hollywood-style changes is now ~100%)... but what we didn't know before, and still do not know now, is the other half of the problem, $P(b|\lnot a)$ (the chance a *fake* script will have similar Hollywood-style changes).

We could assume that a fake script has 50% chance of making each change and item 4 negates one of the others (even though it's really weaker), for a total likelihood ratio of $\frac{1.0}{0.5} + \frac{1.0}{0.5} + \frac{1.0}{0.5} - \frac{0.5}{1.0} = 5.5$, but like before, we have no real ground to defend the 50% guess and so we will be conservative and drop this argument like its sibling argument.

### Legal takedowns

Our observation here is that the two `sendspace` links hosting the PDF went dead within days of the _Anime Vice_ post. We don't know for sure that the links went dead due to takedown, and we don't know for sure that a takedown would be sent only if the script was real. These uncertainties transform what seems like a slam dunk proof of authenticity ("a takedown would be done only if the studio complained, and the studio would complain only if it was real! A takedown was down, therefore it was real!") into just another probabilistic question for us.

Do people send fake takedowns to file hosts? In my experience, a few people (based on watching people upload music and manga etc.) attract trolls dedicated to sending complaints about anything they post, and sometimes entire sites lose their file hosting (eg. in May 2012, [MikuDB](http://mikudb.com/12582/mediafire/) lost hosting for >1000 [Vocaloid](!Wikipedia) & [doujin music](!Wikipedia) albums) but in general downloads work for years afterwards. An instructive sample is to look at the most recent [MediaFire](!Wikipedia)[-related submissions to Reddit](http://www.reddit.com/domain/mediafire.com/) (from the last 8 days when I checked) and see how many of the first 25 are dead for copyright-related reasons; when I tried, only 1 was blocked over copyright^[1 link was dead because "File Belongs to Non-Validated Account" and another link was dead because "The file you attempted to download is an archive that is part of a set of archives. MediaFire does not support unlimited downloads of split archives and the limit for this file has been reached. MediaFire understands the need for users to transfer very large or split archives, up to 10GB per file, and we offer this service starting at $1.50 per month." Neither reason would necessarily be applicable to a 3MB PDF script.], giving a 4% takedown rate. I regard a fake takedown within days as a remote chance, but let's call it 5%.

Do studios send takedowns for fanfiction? No, essentially never: it's a big thing when an author like Anne Rice chooses to crack on fanfiction, or when J.K. Rowling sues the publisher of a fan-work. The 24,246 _DN_ fanfics on `FanFiction.net` stand testimony to the disinclination of studios and publishers to crack down. This chance might as well be zero, but we'll call it 5% anyway for symmetry.

Do studios send takedowns for real scripts? Yes, frequently (much to the [disgust](http://www.mypdfscripts.com/concerning-mediafire-and-the-current-lack-of-scripts/ "Concerning MediaFire and the Current Lack of Scripts...") of script collectors). The previously-mentioned _TMNT_ script leak seems to have been partially suppressed with DMCA takedowns. Isn't it quite plausible that this is what happened? But let's call it just 50% as usual. Maybe plenty of real scripts get posted to news sites and the big studio like Warner Brothers does absolutely nothing about it.

Once we have settled on 5%/5%/50%, it's as routine as usual to work out the new posterior:

1. _a_ = is real
2. _b_ = copies get taken down
3. $P(a)$ = probability of being real = 0.9485
4. $P(\lnot a)$ = probability of being not real = 1 - 0.9485 = 0.05149
5. $P(b|a)$ = probability a real script will have copies taken down = 50% = 0.50
6. $P(b|\lnot a)$ = probability a fake script will have copies taken down = 5%+5% = 0.10

Then Bayes:

$P(a|b) = \frac{P(b|a) \times P(a)}{(P(b|a) \times P(a)) + (P(b|\lnot a) \times P(\lnot a))} =  \frac{0.5 \times 0.9485}{(0.5 \times 0.9485) + (0.1 \times 0.05149)} = 0.9893$

Likelihood ratio:

$\frac{0.50}{0.10} = 5$

## Results

To review and summarize each factor we considered:

Argument/test   $P(a)$   $P(\lnot a)$     $P(b|a)$      $P(b|\lnot a)$     $P(a|b)$    $\frac{P(b|a)}{P(b|\lnot a)}$
--------------- -------- ---------------- ------------- ------------------ ----------- -------------------------------
authorship      0.5      0.5              0.83          0.5                0.643       1.8
name spelling   0.64     0.36             0.5           0.93               0.49        0.538
address         0.49     0.51             0.16          0.16               0.49        1
PDF date        0.49     0.51             0.5           0.25               0.658       2
PDF creator     0.658    0.342            0.99          0.9585             0.6652      1.033
PDF timezone    0.6652   0.3349           0.99          0.881              0.691       1.1237
script length   0.691    0.309            0.99          0.66               0.7703      1.5
Hollywood plot  0.7703   0.2297           ?             ?                  ?           ? (>1)
stylometrics    0.7703   0.2297           0.5           0.1667             0.9096      2.999
dating          0.9096   0.0904           ?             ?                  ?           ? (>1)
credit          0.9096   0.0904           0.99          0.54055            0.9485      1.831
official plot   0.9485   0.05149          ~1.0          ?                  ?           ? (>1)
legal takedown  0.9485   0.05149          0.5           0.10               0.9893      5

The final posterior speaks for itself: 98.9%. By taking into account 9 different factors and thinking about how consistent each factor is with the script being real, we've gone from considerable uncertainty to a surprisingly high value, even after bending over backwards to omit 3 particularly disputable factors.

Is 98% *the* correct posterior? Well, that depends both on whether one accepts each individual analysis and also the original prior of 50%. Suppose one accepted the analysis as presented but believes that actually only 10% of leaked scripts are real? Would such a person wind up believing that the leak is real >50%? How can we answer this question without redoing 9 chained applications of Bayes's theorem? At last we will see the benefit of computing likelihood ratios all along: since likelihood ratios omit the prior $P(a)$, they are expressing something independent, and that turns out to be how much we should increase our prior (whatever it is).

To update using a likelihood ratio, we express our $P(a)$ as instead $\frac{P(a)}{1 - P(a)}$, multiply by the likelihood ratio, and convert back! So for our table: we start with $\frac{0.5}{1 - 0.5} = 1$, multiply by 1.8, 0.538...5:

$\frac{0.5}{1 - 0.5} \times 1.8 \times 0.538 \times 1 \times 2 \times 1.033 \times 1.1237 \times 1.5 \times 2.999 \times 1.831 \times 5 = 92.5895$

And we convert back as $\frac{92.5895}{1+92.5895} = 0.9893$ - like magic, our final posterior reappears. Knowing 89.664 is the factor to multiply by, we can easily run other examples. What of the 10% person? Well:

$\frac{0.10}{1 - 0.10} \times 92.589 = 10.288$ and $\frac{10.288}{1+10.288}=0.9114$

And a 1% person is $\frac{0.01}{1 - 0.01} \times 92.589 = 0.935$ and $\frac{0.935}{1+0.935}=0.483$ Ooh, *almost* to 50%, so we know anyone with a prior of 2% who accepts the analysis will be moved all the way to thinking the script more likely to be true than not (specifically, 0.654).

What if we thought we had the right prior of 50% but we terribly messed up each analysis and each likelihood factor was twice as large/small as it should be? If we cut each likelihood factor's difference from 1 by half[^Haskell-likelihood-factor], then we get a new total likelihood factor of 17.998, and our new posterior is:

$\frac{0.5}{1 - 0.5} \times 17.58 = 17.58$; $\frac{17.58}{1+17.58} = 0.9461$

Oh, that's not so bad.

[^Haskell-likelihood-factor]: The gory details:

    ~~~{.Haskell}
    map (\x -> if x==1 then 1 else (if x>1 then 1+((x-1)/2) else 1-(x/2)))
        [1.8, 0.538,1,2,1.033,1.1237,1.5,2.999,1.831,5]
    [1.4,0.731,1.0,1.5,1.0165,1.06185,1.25,1.9995,1.4155,3.0]

    product (map (\x -> if x==1 then 1 else (if x>1 then 1+((x-1)/2) else 1-(x/2)))
        [1.8, 0.538,1,2,1.033,1.1237,1.5,2.999,1.831,5])
    17.58
    ~~~

What if instead we ignored the 2 arguments with a likelihood ratio greater than 2? Then we get a multiplied likelihood ratio of 3.087[^Haskell-filtered] and from 50% we will go to:

$\frac{0.5}{1 - 0.5} \times 3.087 = 3.087$; $\frac{3.087}{1+3.087} = 0.7553$

[^Haskell-filtered]: Easy enough:

    ~~~{.Haskell}
    product (filter (<2)
        [1.8, 0.538,1,2,1.033,1.1237,1.5,2.999,1.831,5])
    3.0873444556602596
    ~~~

## Benefits
<!-- conclusion section: what tests were surprisingly useful, which were opposite of expected, which were useless, which were double-counting what future lines of enquiry this suggests etc -->
